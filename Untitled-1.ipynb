{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import os \n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data, DataLoader, InMemoryDataset\n",
    "from dataset import SimulationDataset\n",
    "import os\n",
    "import re\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_data_by_file(folders, base_dir):\n",
    "    # Create dictionaries to store output and forcing data per file\n",
    "    images = {}\n",
    "    idx = 0 \n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(base_dir, folder)\n",
    "        for file in os.listdir(folder_path):\n",
    "            if file.endswith('.npz'):\n",
    "                file_path = os.path.join(folder_path, file)\n",
    "                data = np.load(file_path)\n",
    "                images[idx] = data\n",
    "                idx += 1 \n",
    "                \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "base_dir = \"/Users/famkevanree/Library/Mobile Documents/com~apple~CloudDocs/Master TUe/Y2/Q1/2AMM40 Adv. Topics in AI/nuclear-fusion/data/preprocessed\"  # Specify your base directory\n",
    "folders = ['50T_ramp_up', '50T_ramp_down']\n",
    "images = separate_data_by_file(folders, base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class TimeSeriesPerInstanceDataset(Dataset):\n",
    "    def __init__(self, images, normalize=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images (dict): A dictionary where each key is an instance and the value is a dictionary with 'output' and 'forcing'.\n",
    "                           Each entry contains multiple time steps of data.\n",
    "            normalize (bool): Whether to apply normalization to the inputs and targets per variable.\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "        self.normalize = normalize\n",
    "\n",
    "        # Precompute all (instance_idx, time_idx) pairs to ensure each item in the dataset\n",
    "        self.index_pairs = []\n",
    "        for key, data in self.images.items():\n",
    "            timesteps_in_instance = data['output'].shape[0] - 1  # -1 because we need t and t+1\n",
    "            for time_idx in range(timesteps_in_instance):\n",
    "                self.index_pairs.append((key, time_idx))\n",
    "\n",
    "        # Compute the min and max for each channel if normalization is enabled\n",
    "        if self.normalize:\n",
    "            self.min_max_values = self.compute_channel_min_max()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_pairs)\n",
    "\n",
    "    def compute_channel_min_max(self):\n",
    "        \"\"\" Compute the min and max values for each channel (per variable) across all instances. \"\"\"\n",
    "        # Initialize min and max arrays for both input and target channels\n",
    "        input_min, input_max = np.full(8, float('inf')), np.full(8, float('-inf'))  # 8 input channels (6 outputs, 2 forcing)\n",
    "        target_min, target_max = np.full(6, float('inf')), np.full(6, float('-inf'))  # 6 target channels\n",
    "\n",
    "        for _, data in self.images.items():\n",
    "            output = data['output']  # shape (timesteps, 500, 6)\n",
    "            forcing = data['forcing']  # shape (timesteps, 500, 2)\n",
    "\n",
    "            # For each channel in 'output' and 'forcing', update min and max\n",
    "            for i in range(6):  # output has 6 channels\n",
    "                channel_data = output[:, :, i]\n",
    "                input_min[i] = min(input_min[i], np.min(channel_data))\n",
    "                input_max[i] = max(input_max[i], np.max(channel_data))\n",
    "                target_min[i] = min(target_min[i], np.min(channel_data))\n",
    "                target_max[i] = max(target_max[i], np.max(channel_data))\n",
    "\n",
    "            for i in range(2):  # forcing has 2 channels\n",
    "                channel_data = forcing[:, :, i]\n",
    "                input_min[6 + i] = min(input_min[6 + i], np.min(channel_data))\n",
    "                input_max[6 + i] = max(input_max[6 + i], np.max(channel_data))\n",
    "\n",
    "        return {\n",
    "            \"input_min\": input_min, \"input_max\": input_max,\n",
    "            \"target_min\": target_min, \"target_max\": target_max\n",
    "        }\n",
    "\n",
    "    def normalize_per_channel(self, data, min_vals, max_vals):\n",
    "        \"\"\" Normalize each channel separately using Min-Max normalization. \"\"\"\n",
    "        for i in range(data.shape[1]):  # Loop through each channel\n",
    "            data[:, i] = (data[:, i] - min_vals[i]) / (max_vals[i] - min_vals[i] + 1e-6)  # Normalize per channel\n",
    "        return data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Returns normalized input and target. \"\"\"\n",
    "        instance_idx, time_idx = self.index_pairs[idx]\n",
    "        current_data = self.images[instance_idx]\n",
    "\n",
    "        # Extract input (output_t, forcing_{t+1}) and target (output_{t+1})\n",
    "        output_t = current_data['output'][time_idx]  # shape (500, 6)\n",
    "        forcing_t_plus_1 = current_data['forcing'][time_idx + 1]  # shape (500, 2)\n",
    "        target_t_plus_1 = current_data['output'][time_idx + 1]  # shape (500, 6)\n",
    "\n",
    "        # Concatenate output_t and forcing_t_plus_1 to form the input\n",
    "        input_t = np.concatenate((output_t, forcing_t_plus_1), axis=-1)  # shape (500, 8)\n",
    "\n",
    "        # Normalize input and target per channel if normalization is enabled\n",
    "        if self.normalize:\n",
    "            input_t = self.normalize_per_channel(\n",
    "                input_t,\n",
    "                self.min_max_values[\"input_min\"],\n",
    "                self.min_max_values[\"input_max\"]\n",
    "            )\n",
    "            target_t_plus_1 = self.normalize_per_channel(\n",
    "                target_t_plus_1,\n",
    "                self.min_max_values[\"target_min\"],\n",
    "                self.min_max_values[\"target_max\"]\n",
    "            )\n",
    "\n",
    "        # Convert to torch tensors\n",
    "        input_t = torch.tensor(input_t, dtype=torch.float32).permute(1, 0)  # (8, 500)\n",
    "        target_t_plus_1 = torch.tensor(target_t_plus_1, dtype=torch.float32).permute(1, 0)  # (6, 500)\n",
    "\n",
    "        return input_t, target_t_plus_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TimeSeriesPerInstanceDataset(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/NuclearFusion/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Inputs shape = torch.Size([8, 8, 500]), Targets shape = torch.Size([8, 6, 500])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "    # Inputs: Shape (batch_size, time_steps-1, coordinates, 8)\n",
    "    # Targets: Shape (batch_size, time_steps-1, coordinates, 6)\n",
    "    print(f\"Batch {batch_idx}: Inputs shape = {inputs.shape}, Targets shape = {targets.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models import Forward, Prior, Posterior, Decoder\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import keras, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNEncoderDecoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNEncoderDecoder, self).__init__()\n",
    "\n",
    "        # Increase the model capacity (more layers, more filters)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(8, 128, kernel_size=3, padding=1),  # Increased from 64 to 128\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 256, kernel_size=3, padding=1),  # Increased from 128 to 256\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(256, 512, kernel_size=3, padding=1),  # Increased from 256 to 512\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose1d(128, 6, kernel_size=3, padding=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 0.0039\n",
      "Epoch [2/1000], Loss: 0.0002\n",
      "Epoch [3/1000], Loss: 0.0001\n",
      "Epoch [4/1000], Loss: 0.0001\n",
      "Epoch [5/1000], Loss: 0.0001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Clear previous gradients\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Backpropagate the loss\u001b[39;00m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()  \u001b[38;5;66;03m# Update the weights\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Accumulate loss for this epoch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/NuclearFusion/lib/python3.11/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/NuclearFusion/lib/python3.11/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/NuclearFusion/lib/python3.11/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 10  \n",
    "model = CNNEncoderDecoder()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=0)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "# Track the training loss over time\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Iterate over the DataLoader (get mini-batches)\n",
    "    for inputs, targets in dataloader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)  # Predictions\n",
    "        loss = criterion(outputs, targets)  # Calculate loss\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        loss.backward()  # Backpropagate the loss\n",
    "        optimizer.step()  # Update the weights\n",
    "\n",
    "        # Accumulate loss for this epoch\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Average loss per batch for this epoch\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "\n",
    "    # Print loss after each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output min: 1.0\n",
      "Model output max: 1.0\n",
      "Target min: 0.0\n",
      "Target max: 2.3947370289835698e+20\n"
     ]
    }
   ],
   "source": [
    "# Before loss.backward() inside your training loop, print output stats\n",
    "print(\"Model output min:\", outputs.min().item())\n",
    "print(\"Model output max:\", outputs.max().item())\n",
    "print(\"Target min:\", targets.min().item())\n",
    "print(\"Target max:\", targets.max().item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NuclearFusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
