{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Split data in train, validation, test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../nuclear-fusion/data/preprocessed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "from dataset import SimulationDataset\n",
    "simulationdataset = SimulationDataset(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sampler that uses Time Adjusted Sampling as described in Appendix B\n",
    "from sampler import TimeAdjustedSampler\n",
    "sampler = TimeAdjustedSampler(simulationdataset, batch_size=16, omega=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup dataloader\n",
    "from torch.utils.data import DataLoader \n",
    "dataloader = DataLoader(simulationdataset, batch_sampler=sampler, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/coder/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/coder/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/coder/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/coder/persistent/TokamakSimulation/dataset.py\", line 123, in __getitem__\n    temp_idx = np.searchsorted(self.cumulative_lengths, idx, side='right') - 1\n  File \"/home/coder/.local/lib/python3.10/site-packages/numpy/_core/fromnumeric.py\", line 1534, in searchsorted\n    return _wrapfunc(a, 'searchsorted', v, side=side, sorter=sorter)\n  File \"/home/coder/.local/lib/python3.10/site-packages/numpy/_core/fromnumeric.py\", line 54, in _wrapfunc\n    return _wrapit(obj, method, *args, **kwds)\n  File \"/home/coder/.local/lib/python3.10/site-packages/numpy/_core/fromnumeric.py\", line 46, in _wrapit\n    result = getattr(arr, method)(*args, **kwds)\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1344\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1343\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1370\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1370\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_utils.py:706\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 706\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/coder/.local/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/coder/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/coder/.local/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/coder/persistent/TokamakSimulation/dataset.py\", line 123, in __getitem__\n    temp_idx = np.searchsorted(self.cumulative_lengths, idx, side='right') - 1\n  File \"/home/coder/.local/lib/python3.10/site-packages/numpy/_core/fromnumeric.py\", line 1534, in searchsorted\n    return _wrapfunc(a, 'searchsorted', v, side=side, sorter=sorter)\n  File \"/home/coder/.local/lib/python3.10/site-packages/numpy/_core/fromnumeric.py\", line 54, in _wrapfunc\n    return _wrapit(obj, method, *args, **kwds)\n  File \"/home/coder/.local/lib/python3.10/site-packages/numpy/_core/fromnumeric.py\", line 46, in _wrapit\n    result = getattr(arr, method)(*args, **kwds)\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.\n"
     ]
    }
   ],
   "source": [
    "for batch in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timesteps available [100, 500, 1000]\n",
      "probability distribution from which we sample length:  [0.0625 0.3125 0.625 ]\n",
      "Sampled length in timesteps: 1000 for sample outcome 2\n",
      "Correspondings idxs: 192-288\n",
      "Sampled idx in range:  275\n",
      "Shape of output:  (991, 500, 6)\n",
      "Number of batches taken from simulation:  24\n",
      "\tShape of batch X:  (20, 500, 6)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sampling strategy\n",
    "\n",
    "batch_size = 16\n",
    "omega = 20\n",
    "\n",
    "# get available timesteps and sampling distribution\n",
    "timesteps = simulationdataset.timesteps\n",
    "p_t = simulationdataset.calculate_p_t(omega=omega)\n",
    "\n",
    "# sample\n",
    "sample = np.random.choice(len(p_t), p=p_t)\n",
    "timestep = timesteps[sample]\n",
    "\n",
    "# find idxs of simulation of length t\n",
    "idx_start = simulationdataset.cumulative_lengths[sample]\n",
    "idx_end = simulationdataset.cumulative_lengths[sample + 1]\n",
    "\n",
    "# uniformly choose idx to sample and get its simulation\n",
    "idx = np.random.randint(idx_start, idx_end)\n",
    "output, forcing = simulationdataset.__getitem__(idx)\n",
    "\n",
    "batches = []\n",
    "\n",
    "t_start = 0\n",
    "while True:\n",
    "    t_middle = t_start + omega\n",
    "    t_end = t_start + 2*omega\n",
    "\n",
    "    # check if there is enough room for, if not, break loop\n",
    "    if t_end > output.shape[0]:\n",
    "        break\n",
    "\n",
    "    # fetch X data\n",
    "    X = output[t_start:t_middle,:,:]\n",
    "    F = forcing[t_start:t_end,:,:]\n",
    "    Y = output[t_middle:t_end,:,:]\n",
    "    \n",
    "    # append to batch\n",
    "    batches.append([X, F, Y])\n",
    "\n",
    "    # go to next batch\n",
    "    t_start += 2*omega\n",
    "\n",
    "print(\"timesteps available\", timesteps)\n",
    "print(\"probability distribution from which we sample length: \", p_t)\n",
    "print(f\"Sampled length in timesteps: {timestep} for sample outcome {sample}\")\n",
    "print(f\"Correspondings idxs: {idx_start}-{idx_end}\")\n",
    "print(\"Sampled idx in range: \", idx)\n",
    "print(\"Shape of output: \", output.shape)\n",
    "print(\"Number of batches taken from simulation: \", len(batches))\n",
    "print(\"\\tShape of batch X: \", batches[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tShape of batch X:  (40, 500, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\tShape of batch X: \", batches[1][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
